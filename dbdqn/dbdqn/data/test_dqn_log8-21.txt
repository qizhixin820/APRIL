state_dim = 100, action_dim = 4818
init_state = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.]
step = 0
choose action by q_vals: [ 1.3129242e+04  2.3087144e-01  9.1040488e+03 ... -5.2212596e+00
 -4.2729182e+00 -6.9481778e-01]
action = 4
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#teacherOf']
reward = -5109.94553565979
state = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0.]
step = 1
choose action by q_vals: [ 1.3129242e+04  2.3087144e-01  9.1040488e+03 ... -5.2212596e+00
 -4.2729182e+00 -6.9481778e-01]
action = 0
parsed_action = ['http://www.w3.org/1999/02/22-rdf-syntax-ns#type']
reward = -1249.4211196899414
state = [ 5 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 2
choose action by q_vals: [ 3.3044900e+05  5.9120727e+00  2.2912016e+05 ... -1.3091449e+02
 -1.0752319e+02 -1.8315683e+01]
action = 5
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#undergraduateDegreeFrom']
reward = 14970.955848693848
state = [ 5 19  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 3
choose action by q_vals: [ 5.9743619e+05  1.0292732e+01  4.1423691e+05 ... -2.3700542e+02
 -1.9465692e+02 -3.3251198e+01]
action = 15
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#advisor']
reward = 5143.2976722717285
state = [ 5 19  1 19  6 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 4
choose action by q_vals: [ 9.2836662e+05  1.5832655e+01  6.4369088e+05 ... -3.6813654e+02
 -3.0194443e+02 -5.2044342e+01]
action = 16
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#publicationAuthor']
reward = 173.2795238494873
state = [ 5 19  1 19  6 19 16 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 5
choose action by q_vals: [ 1.3860586e+06  2.4019768e+01  9.6103512e+05 ... -5.5002875e+02
 -4.5039154e+02 -7.7298943e+01]
action = 13
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#memberOf']
reward = -453.65142822265625
state = [ 5 19  1 19  6 19 16 19 17 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 6
choose action by q_vals: [ 1.8583166e+06  3.1805534e+01  1.2884784e+06 ... -7.3756342e+02
 -6.0408282e+02 -1.0332478e+02]
action = 9
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#emailAddress']
reward = 808.0828189849854
state = [ 5 19  1 19  6 19 16 19 17 19 14 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 7
choose action by q_vals: [ 2.2884470e+06  3.9362103e+01  1.5867121e+06 ... -9.0801605e+02
 -7.4341302e+02 -1.2722518e+02]
action = 3
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#subOrganizationOf']
reward = 4904.360055923462
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 8
choose action by q_vals: [ 2.6646645e+06  4.5863091e+01  1.8475661e+06 ... -1.0576670e+03
 -8.6671094e+02 -1.4822342e+02]
action = 8
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#worksFor']
reward = 446.8703269958496
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 9
choose action by q_vals: [ 2.9631442e+06  5.1340996e+01  2.0545172e+06 ... -1.1760094e+03
 -9.6330255e+02 -1.6436795e+02]
action = 181
parsed_action = [6, 1, 3]
reward = 528.7246704101562
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 10
choose action by q_vals: [ 2.9631442e+06  5.1340996e+01  2.0545172e+06 ... -1.1760094e+03
 -9.6330255e+02 -1.6436795e+02]
action = 53
parsed_action = [3, 2, 3]
reward = 650.0847339630127
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 11
choose action by q_vals: [ 3.3222885e+06  5.7475273e+01  2.3035332e+06 ... -1.3186274e+03
 -1.0807606e+03 -1.8403574e+02]
action = 101
parsed_action = [4, 3, 3]
reward = -942.3727989196777
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 12
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 18
parsed_action = [2, 1, 0]
reward = -87.34631538391113
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 13
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 98
parsed_action = [4, 3, 0]
reward = 747.9395866394043
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 14
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 66
parsed_action = [4, 1, 0]
reward = 728.1508445739746
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 15
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 226
parsed_action = [6, 4, 0]
reward = -779.4299125671387
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 16
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 130
parsed_action = [5, 2, 0]
reward = 709.8002433776855
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 17
choose action by q_vals: [ 3.6568810e+06  6.3594742e+01  2.5355238e+06 ... -1.4515483e+03
 -1.1898546e+03 -2.0310780e+02]
action = 115
parsed_action = [5, 1, 1]
reward = -532.0260524749756
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 18
choose action by q_vals: [ 4.1693660e+06  7.1937935e+01  2.8908590e+06 ... -1.6554869e+03
 -1.3565547e+03 -2.3197513e+02]
action = 163
parsed_action = [5, 4, 1]
reward = -975.1811027526855
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 19
choose action by q_vals: [ 4.6748265e+06  8.1184937e+01  3.2413238e+06 ... -1.8563016e+03
 -1.5206947e+03 -2.6039154e+02]
action = 51
parsed_action = [3, 2, 1]
reward = -1658.602237701416
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 20
choose action by q_vals: [ 5.3042305e+06  9.3225304e+01  3.6777200e+06 ... -2.1053738e+03
 -1.7262230e+03 -2.9392795e+02]
action = 323
parsed_action = [7, 5, 1]
reward = 3665.5640602111816
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 21
choose action by q_vals: [ 5.3042305e+06  9.3225304e+01  3.6777200e+06 ... -2.1053738e+03
 -1.7262230e+03 -2.9392795e+02]
action = 276
parsed_action = [7, 2, 2]
reward = 640.5797004699707
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 22
choose action by q_vals: [ 5.3042305e+06  9.3225304e+01  3.6777200e+06 ... -2.1053738e+03
 -1.7262230e+03 -2.9392795e+02]
action = 99
parsed_action = [4, 3, 1]
reward = -1346.874713897705
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 23
choose action by q_vals: [ 5.6053075e+06  9.8195877e+01  3.8864738e+06 ... -2.2245381e+03
 -1.8241790e+03 -3.1063986e+02]
action = 211
parsed_action = [6, 3, 1]
reward = 47.3480224609375
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 24
choose action by q_vals: [ 5.6053075e+06  9.8195877e+01  3.8864738e+06 ... -2.2245381e+03
 -1.8241790e+03 -3.1063986e+02]
action = 340
parsed_action = [7, 6, 2]
reward = -447.5133419036865
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 25
choose action by q_vals: [ 5.6053075e+06  9.8195877e+01  3.8864738e+06 ... -2.2245381e+03
 -1.8241790e+03 -3.1063986e+02]
action = 164
parsed_action = [5, 4, 2]
reward = 1282.254695892334
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 26
choose action by q_vals: [ 5.6053075e+06  9.8195877e+01  3.8864738e+06 ... -2.2245381e+03
 -1.8241790e+03 -3.1063986e+02]
action = 131
parsed_action = [5, 2, 1]
reward = -2466.360569000244
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 27
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 114
parsed_action = [5, 1, 0]
reward = 1329.9682140350342
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 28
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 530
parsed_action = [9, 5, 0]
reward = -1873.3980655670166
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 29
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 52
parsed_action = [3, 2, 2]
reward = -2375.2715587615967
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 30
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 836
parsed_action = [11, 7, 2]
reward = 319.8554515838623
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 31
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 228
parsed_action = [6, 4, 2]
reward = 3521.0866928100586
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 32
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 548
parsed_action = [9, 6, 2]
reward = -1372.0788955688477
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 33
choose action by q_vals: [ 6.0575235e+06  1.0600505e+02  4.2000185e+06 ... -2.4041553e+03
 -1.9721394e+03 -3.3615027e+02]
action = 644
parsed_action = [10, 4, 2]
reward = -4271.055698394775
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 34
choose action by q_vals: [ 6.44454000e+06  1.12503876e+02  4.46835450e+06 ... -2.55771875e+03
 -2.09800317e+03 -3.57205994e+02]
action = 802
parsed_action = [11, 5, 0]
reward = -1875.2858638763428
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 35
choose action by q_vals: [ 6.82822000e+06  1.18862335e+02  4.73438350e+06 ... -2.71070215e+03
 -2.22304370e+03 -3.78429749e+02]
action = 675
parsed_action = [10, 6, 1]
reward = -4838.91224861145
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 36
choose action by q_vals: [ 6.82822000e+06  1.18862335e+02  4.73438350e+06 ... -2.71070215e+03
 -2.22304370e+03 -3.78429749e+02]
action = 756
parsed_action = [11, 2, 2]
reward = 4036.53621673584
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 37
choose action by q_vals: [ 6.82822000e+06  1.18862335e+02  4.73438350e+06 ... -2.71070215e+03
 -2.22304370e+03 -3.78429749e+02]
action = 149
parsed_action = [5, 3, 3]
reward = 4555.079936981201
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 38
choose action by q_vals: [ 6.82822000e+06  1.18862335e+02  4.73438350e+06 ... -2.71070215e+03
 -2.22304370e+03 -3.78429749e+02]
action = 595
parsed_action = [10, 1, 1]
reward = -3176.290988922119
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 39
choose action by q_vals: [ 6.82822000e+06  1.18862335e+02  4.73438350e+06 ... -2.71070215e+03
 -2.22304370e+03 -3.78429749e+02]
action = 854
parsed_action = [11, 8, 4]
reward = -2063.5366439819336
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 40
choose action by q_vals: [ 7.2748250e+06  1.2695456e+02  5.0440430e+06 ... -2.8872905e+03
 -2.3685393e+03 -4.0269159e+02]
action = 2
parsed_action = ['http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl#name']
reward = 7550.087690353394
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 41
choose action by q_vals: [ 7.5231740e+06  1.3126459e+02  5.2162420e+06 ... -2.9863855e+03
 -2.4498184e+03 -4.1594196e+02]
action = 809
parsed_action = [11, 5, 7]
reward = -14216.080665588379
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 42
choose action by q_vals: [ 7.5231740e+06  1.3126459e+02  5.2162420e+06 ... -2.9863855e+03
 -2.4498184e+03 -4.1594196e+02]
action = 947
parsed_action = [12, 4, 1]
reward = 5127.932071685791
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 43
choose action by q_vals: [ 7.5231740e+06  1.3126459e+02  5.2162420e+06 ... -2.9863855e+03
 -2.4498184e+03 -4.1594196e+02]
action = 85
parsed_action = [4, 2, 3]
reward = 6001.697540283203
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 44
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 1157
parsed_action = [13, 6, 3]
reward = 675.992488861084
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 45
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 872
parsed_action = [11, 9, 6]
reward = -1933.3820343017578
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 46
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 34
parsed_action = [3, 1, 0]
reward = -292.65284538269043
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 47
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 100
parsed_action = [4, 3, 2]
reward = 987.3175621032715
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 48
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 84
parsed_action = [4, 2, 2]
reward = 2829.5137882232666
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
step = 49
choose action by q_vals: [ 7.6242200e+06  1.3309634e+02  5.2863045e+06 ... -3.0275137e+03
 -2.4833926e+03 -4.2111691e+02]
action = 307
parsed_action = [7, 4, 1]
reward = -16046.458005905151
state = [ 5 19  1 19  6 19 16 19 17 19 14 19 10 19  4 19  9 19  6  1 19  6 16 19
  5 17 19 16 17 19  6  1 19  6 16 19  1 17 19  6  1 16 19  6 17 16 19  6
  4 16 19  3 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
  0  0  0  0]
last epoch max return is 22329.713582992554at step 21
using time: 5030.665688276291s
